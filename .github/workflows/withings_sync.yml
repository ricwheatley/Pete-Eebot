name: Withings Daily Sync

on:
  schedule:
    - cron: "17 4 * * *"   # daily 04:17 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Run Withings sync (CSV upsert)
        env:
          WITHINGS_CLIENT_ID:     ${{ secrets.WITHINGS_CLIENT_ID }}
          WITHINGS_CLIENT_SECRET: ${{ secrets.WITHINGS_CLIENT_SECRET }}
          WITHINGS_REDIRECT_URI:  ${{ secrets.WITHINGS_REDIRECT_URI }}
          WITHINGS_REFRESH_TOKEN: ${{ secrets.WITHINGS_REFRESH_TOKEN }}
          WITHINGS_DAYS_BACK: "14"
          WEIGHT_CSV: knowledge/weight_log.csv
          ACTIVITY_CSV: knowledge/activity_log.csv
        run: |
          python - << 'PY'
          import os, csv, requests, sys
          from datetime import datetime, timedelta, timezone
          from pathlib import Path

          TOKEN_URL   = "https://wbsapi.withings.net/v2/oauth2"
          MEASURE_URL = "https://wbsapi.withings.net/measure"
          ACT_URL     = "https://wbsapi.withings.net/v2/measure"

          def ts(dt): return int(dt.timestamp())
          def ymd(d): return d.strftime("%Y-%m-%d")

          def ensure_csv(path, header):
              Path(path).parent.mkdir(parents=True, exist_ok=True)
              if not Path(path).exists():
                  with open(path,"w",newline="",encoding="utf-8") as f:
                      csv.writer(f).writerow(header)

          def upsert_by_date(path, header, row):
              ensure_csv(path, header)
              rows=[]; idx=-1
              with open(path,"r",newline="",encoding="utf-8") as f:
                  r=csv.DictReader(f)
                  for i,x in enumerate(r):
                      rows.append(x)
                      if x.get("date")==row.get("date"):
                          idx=i
              if idx>=0:
                  rows[idx].update(row)
              else:
                  rows.append(row)
                  rows.sort(key=lambda x:x.get("date",""))
              with open(path,"w",newline="",encoding="utf-8") as f:
                  w=csv.DictWriter(f,fieldnames=header); w.writeheader()
                  for x in rows: w.writerow({k:x.get(k,"") for k in header})

          cid=os.environ["WITHINGS_CLIENT_ID"]
          csec=os.environ["WITHINGS_CLIENT_SECRET"]
          rt  =os.environ["WITHINGS_REFRESH_TOKEN"]
          days=int(os.environ.get("WITHINGS_DAYS_BACK","14"))
          weight_csv=os.environ.get("WEIGHT_CSV","knowledge/weight_log.csv")
          act_csv=os.environ.get("ACTIVITY_CSV","knowledge/activity_log.csv")

          # Refresh token
          resp=requests.post(TOKEN_URL,data={
              "action":"requesttoken","grant_type":"refresh_token",
              "client_id":cid,"client_secret":csec,"refresh_token":rt
          },timeout=30).json()
          if resp.get("status")!=0:
              print("Token refresh failed:", resp); sys.exit(1)
          access=resp["body"]["access_token"]

          hdr={"Authorization":f"Bearer {access}"}
          end=datetime.now(timezone.utc).date()
          start=end - timedelta(days=days)

          # Weight and composition
          w_hdr=["date","weight_kg","body_fat_pct","muscle_mass_kg","water_pct","source","notes"]
          ensure_csv(weight_csv,w_hdr)
          r=requests.get(MEASURE_URL,headers=hdr,params={
              "action":"getmeas","meastypes":"1,6,76,77","category":1,
              "startdate":ts(datetime.combine(start, datetime.min.time(), tzinfo=timezone.utc)),
              "enddate":ts(datetime.combine(end, datetime.min.time(), tzinfo=timezone.utc))
          },timeout=30).json()
          if r.get("status")==0:
              for grp in r["body"].get("measuregrps",[]):
                  dt=datetime.fromtimestamp(grp["date"],tz=timezone.utc).date().strftime("%Y-%m-%d")
                  def val(t):
                      for m in grp.get("measures",[]):
                          if m.get("type")==t:
                              return m["value"]*(10**m["unit"])
                      return None
                  row={
                      "date": dt,
                      "weight_kg": f'{val(1):.2f}' if (val(1) is not None) else "",
                      "body_fat_pct": f'{val(6):.2f}' if (val(6) is not None) else "",
                      "muscle_mass_kg": f'{val(76):.2f}' if (val(76) is not None) else "",
                      "water_pct": f'{val(77):.2f}' if (val(77) is not None) else "",
                      "source":"withings","notes":""
                  }
                  upsert_by_date(weight_csv,w_hdr,row)

          # Daily activity
          a_hdr=["date","steps","exercise_minutes","avg_hr_bpm","resting_hr_bpm","calories_out","workout_type","workout_duration_min","source"]
          ensure_csv(act_csv,a_hdr)
          r=requests.get(ACT_URL,headers=hdr,params={
              "action":"getactivity","startdateymd":ymd(start),"enddateymd":ymd(end)
          },timeout=30).json()
          if r.get("status")==0:
              for a in r["body"].get("activities",[]):
                  row={
                      "date": a.get("date",""),
                      "steps": a.get("steps",""),
                      "exercise_minutes": a.get("active_minutes", a.get("soft","")),
                      "avg_hr_bpm": a.get("hr_average",""),
                      "resting_hr_bpm": a.get("hr_min",""),
                      "calories_out": a.get("calories",""),
                      "workout_type": "",
                      "workout_duration_min": "",
                      "source":"withings"
                  }
                  upsert_by_date(act_csv,a_hdr,row)
          PY

      - name: Build daily summary JSON for GitHub Pages
        run: |
          mkdir -p docs summaries
          python - << 'PY'
          import csv, json, pathlib, datetime
          p_w = pathlib.Path("knowledge/weight_log.csv")
          p_a = pathlib.Path("knowledge/activity_log.csv")

          def last_row(p):
              if not p.exists(): return {}
              with p.open(encoding="utf-8") as f:
                  rows = list(csv.DictReader(f))
                  return rows[-1] if rows else {}

          w = last_row(p_w)
          a = last_row(p_a)
          today = datetime.date.today().isoformat()
          out = {
            "date": today,
            "weight_kg": w.get("weight_kg"),
            "body_fat_pct": w.get("body_fat_pct"),
            "steps": a.get("steps"),
            "exercise_minutes": a.get("exercise_minutes"),
            "avg_hr_bpm": a.get("avg_hr_bpm"),
            "calories_out": a.get("calories_out"),
            "source": "withings"
          }
          pathlib.Path("docs").mkdir(parents=True, exist_ok=True)
          pathlib.Path("docs/daily.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
          pathlib.Path("summaries").mkdir(parents=True, exist_ok=True)
          pathlib.Path(f"summaries/{today}.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
          print(json.dumps(out))
          PY

      - name: Commit CSV and summary updates
        run: |
          if [[ -n "$(git status --porcelain knowledge/*.csv docs/daily.json summaries 2>/dev/null || true)" ]]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add knowledge/*.csv docs/daily.json summaries || true
            git commit -m "chore: update Withings logs and daily summary"
            git push
          else
            echo "No changes to commit."
          fi