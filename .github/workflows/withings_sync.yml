name: Withings Daily Measures Only

on:
  schedule:
    - cron: "0 3 * * *"   # 03:00 UTC daily (Europe/London date handled in code)
  workflow_dispatch:

permissions:
  contents: write   # commit CSV/JSON
  # GITHUB_TOKEN cannot update repository secrets. Use a PAT in GH_SECRETS_TOKEN.

jobs:
  measures:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests pynacl

      - name: Fetch previous-day measures, rotate token, write CSV + JSON
        env:
          WITHINGS_CLIENT_ID:     ${{ vars.WITHINGS_CLIENT_ID }}
          WITHINGS_CLIENT_SECRET: ${{ secrets.WITHINGS_CLIENT_SECRET }}
          WITHINGS_REDIRECT_URI:  ${{ vars.WITHINGS_REDIRECT_URI }}
          WITHINGS_REFRESH_TOKEN: ${{ secrets.WITHINGS_REFRESH_TOKEN }}

          # Output paths
          WEIGHT_CSV: knowledge/weight_log.csv

          # For secret rotation
          REPO_FULL_NAME: ${{ github.repository }}           # owner/repo
          GH_SECRETS_TOKEN: ${{ secrets.GH_SECRETS_TOKEN }}  # PAT with repo:actions write (to update secrets)
        run: |
          python - << 'PY'
          from __future__ import annotations
          import os, csv, json, requests, sys, base64
          from pathlib import Path
          from datetime import datetime, timedelta, timezone
          from zoneinfo import ZoneInfo
          from nacl import public

          # ---- Constants
          TOKEN_URL   = "https://wbsapi.withings.net/v2/oauth2"
          MEASURE_URL = "https://wbsapi.withings.net/measure"  # GET, action=getmeas
          SECRET_NAME = "WITHINGS_REFRESH_TOKEN"

          # ---- Helpers
          def ensure_csv(path: str, header: list[str]) -> None:
            p = Path(path)
            p.parent.mkdir(parents=True, exist_ok=True)
            if not p.exists():
              with p.open("w", newline="", encoding="utf-8") as f:
                csv.writer(f).writerow(header)

          def redact_token(tok: str | None) -> str | None:
            if not tok or not isinstance(tok, str): return tok
            return tok[:4] + "..." + tok[-4:] if len(tok) > 8 else "****"

          def redact_body(obj):
            if isinstance(obj, dict):
              red = {}
              for k, v in obj.items():
                lk = k.lower()
                if lk in {"access_token","refresh_token","token"} and isinstance(v, str):
                  red[k] = redact_token(v)
                elif isinstance(v, (dict, list)):
                  red[k] = redact_body(v)
                else:
                  red[k] = v
              return red
            if isinstance(obj, list):
              return [redact_body(x) for x in obj]
            return obj

          def write_redacted(path: Path, status_code: int | None, body) -> None:
            path.parent.mkdir(parents=True, exist_ok=True)
            safe = {"status_code": status_code, "body": redact_body(body)}
            path.write_text(json.dumps(safe, indent=2), encoding="utf-8")

          # GitHub Secrets helpers
          def gh_headers():
            tok = os.environ.get("GH_SECRETS_TOKEN")
            if not tok:
              raise RuntimeError("GH_SECRETS_TOKEN not set. Create a PAT with repo permissions to update secrets.")
            return {"Authorization": f"Bearer {tok}", "Accept": "application/vnd.github+json"}

          def get_public_key(owner_repo: str) -> dict:
            url = f"https://api.github.com/repos/{owner_repo}/actions/secrets/public-key"
            r = requests.get(url, headers=gh_headers(), timeout=30)
            if r.status_code != 200:
              raise RuntimeError(f"Failed to get repo public key: {r.status_code} {r.text}")
            return r.json()

          def seal_with_public_key(public_key_b64: str, value: str) -> str:
            key_bytes = base64.b64decode(public_key_b64)
            pk = public.PublicKey(key_bytes)
            sealed = public.SealedBox(pk).encrypt(value.encode("utf-8"))
            return base64.b64encode(sealed).decode("utf-8")

          def put_secret(owner_repo: str, secret_name: str, ciphertext: str, key_id: str) -> None:
            url = f"https://api.github.com/repos/{owner_repo}/actions/secrets/{secret_name}"
            payload = {"encrypted_value": ciphertext, "key_id": key_id}
            r = requests.put(url, headers=gh_headers(), json=payload, timeout=30)
            if r.status_code not in (201, 204):
              raise RuntimeError(f"Failed to update secret {secret_name}: {r.status_code} {r.text}")

          # ---- Determine the previous day in Europe/London, and UTC timestamps covering that local day
          london = ZoneInfo("Europe/London")
          now_ldn = datetime.now(tz=london)
          prev_ldn_date = (now_ldn.date() - timedelta(days=1))
          start_ldn = datetime(prev_ldn_date.year, prev_ldn_date.month, prev_ldn_date.day, tzinfo=london)
          end_ldn   = start_ldn + timedelta(days=1) - timedelta(seconds=1)

          # Convert to UTC epoch seconds for Withings API
          start_utc = int(start_ldn.astimezone(timezone.utc).timestamp())
          end_utc   = int(end_ldn.astimezone(timezone.utc).timestamp())

          # ---- Paths
          weight_csv = os.environ.get("WEIGHT_CSV", "knowledge/weight_log.csv")
          raw_dir = Path("docs/raw"); raw_dir.mkdir(parents=True, exist_ok=True)

          # ---- 1) Refresh the token
          tok_resp = requests.post(TOKEN_URL, data={
            "action": "requesttoken",
            "grant_type": "refresh_token",
            "client_id": os.environ["WITHINGS_CLIENT_ID"],
            "client_secret": os.environ["WITHINGS_CLIENT_SECRET"],
            "refresh_token": os.environ["WITHINGS_REFRESH_TOKEN"],
          }, timeout=45)

          try:
            tok_json = tok_resp.json()
          except Exception:
            tok_json = {"non_json": tok_resp.text}

          write_redacted(raw_dir / "withings_token.json", tok_resp.status_code, tok_json)

          if tok_json.get("status") != 0:
            print("Token refresh failed:", json.dumps(tok_json, indent=2))
            sys.exit(1)

          body = tok_json.get("body", {})
          access_token = body.get("access_token")
          new_refresh  = body.get("refresh_token")
          if not access_token or not new_refresh:
            print("Unexpected token response:", json.dumps(redact_body(tok_json), indent=2))
            sys.exit(1)

          # ---- 2) Rotate the stored refresh token in repo secrets
          try:
            owner_repo = os.environ["REPO_FULL_NAME"]
            pk = get_public_key(owner_repo)
            ciphertext = seal_with_public_key(pk["key"], new_refresh)
            put_secret(owner_repo, SECRET_NAME, ciphertext, pk["key_id"])
            print("Updated repo secret WITHINGS_REFRESH_TOKEN")
          except Exception as e:
            print("WARNING: could not update WITHINGS_REFRESH_TOKEN:", e)
            # Fail closed to avoid tomorrow using an invalidated refresh token
            sys.exit(1)

          # ---- 3) Fetch measures for the previous Europe/London day
          headers = {"Authorization": f"Bearer {access_token}"}
          params = {
            "action": "getmeas",
            # 1=weight(kg), 6=Fat%, 76=muscle mass(kg), 77=water%
            "meastypes": "1,6,76,77",
            "category": 1,
            "startdate": start_utc,
            "enddate": end_utc,
          }
          meas_resp = requests.get(MEASURE_URL, headers=headers, params=params, timeout=45)

          try:
            meas_json = meas_resp.json()
          except Exception:
            meas_json = {"non_json": meas_resp.text}

          write_redacted(raw_dir / f"withings_measures_{prev_ldn_date.isoformat()}.json", meas_resp.status_code, meas_json)

          # ---- 4) Parse to daily rollup
          weight_by_day = {}  # date -> dict
          if meas_json.get("status") == 0:
            for grp in (meas_json.get("body", {}) or {}).get("measuregrps", []) or []:
              dt = datetime.fromtimestamp(grp["date"], tz=timezone.utc).astimezone(london)
              d  = dt.date().isoformat()
              def val(t):
                for m in grp.get("measures", []) or []:
                  if m.get("type") == t:
                    return m["value"] * (10 ** m["unit"])
                return None
              # last reading of the day wins
              weight_by_day[d] = {
                "date": d,
                "weight_kg": f"{val(1):.2f}" if val(1) is not None else "",
                "body_fat_pct": f"{val(6):.2f}" if val(6) is not None else "",
                "muscle_mass_kg": f"{val(76):.2f}" if val(76) is not None else "",
                "water_pct": f"{val(77):.2f}" if val(77) is not None else "",
                "source": "withings",
                "notes": ""
              }

          # Ensure CSV exists, then upsert only the previous day
          w_hdr = ["date","weight_kg","body_fat_pct","muscle_mass_kg","water_pct","source","notes"]
          ensure_csv(weight_csv, w_hdr)

          # Read existing rows
          existing = {}
          try:
            with open(weight_csv, "r", newline="", encoding="utf-8") as f:
              for r in csv.DictReader(f):
                existing[r["date"]] = r
          except FileNotFoundError:
            pass

          d = prev_ldn_date.isoformat()
          # Preserve any historical row if there was no new measure
          new_row = weight_by_day.get(d, existing.get(d, {
            "date": d, "weight_kg":"", "body_fat_pct":"", "muscle_mass_kg":"", "water_pct":"",
            "source":"withings", "notes":""
          }))
          existing[d] = new_row

          # Write all rows back sorted by date
          with open(weight_csv, "w", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=w_hdr)
            w.writeheader()
            for key in sorted(existing.keys()):
              w.writerow({k: existing[key].get(k, "") for k in w_hdr})

          # Also emit a simple per-day JSON file for the previous day, and update daily.json
          Path("docs/days").mkdir(parents=True, exist_ok=True)
          day_json = {
            "date": new_row["date"],
            "weight_kg": new_row["weight_kg"] or None,
            "body_fat_pct": new_row["body_fat_pct"] or None,
            "muscle_mass_kg": new_row["muscle_mass_kg"] or None,
            "water_pct": new_row["water_pct"] or None,
            "source": "withings",
            "is_partial_weight": not bool(new_row["weight_kg"])
          }
          Path(f"docs/days/{d}.json").write_text(json.dumps(day_json, indent=2), encoding="utf-8")
          Path("docs/daily.json").write_text(json.dumps(day_json, indent=2), encoding="utf-8")

          print(json.dumps({
            "europe_london_prev_day": d,
            "utc_window": {"start": start_utc, "end": end_utc},
            "csv": weight_csv
          }))
          PY

      - name: Commit updates (CSV + redacted RAW + JSON)
        run: |
          if [[ -n "$(git status --porcelain knowledge/*.csv docs 2>/dev/null || true)" ]]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add knowledge/*.csv docs
            git commit -m "chore: measures-only sync, prev Europe/London day, token rotation, redacted RAW"
            git push
          else
            echo "No changes to commit."
          fi
